# GPU Platform Requirements
# Core dependencies for GPU-accelerated LLM hosting

# GPU Monitoring
nvidia-ml-py3>=12.535.77
pynvml>=11.5.0

# PyTorch (CUDA 11.8 version)
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# Transformers and Model Loading
transformers>=4.35.0
accelerate>=0.24.0
bitsandbytes>=0.41.0
sentencepiece>=0.1.99

# API Server
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
websockets>=12.0
python-multipart>=0.0.6

# Model Formats
safetensors>=0.4.0
huggingface-hub>=0.17.0

# Performance and Optimization
einops>=0.7.0
flash-attn>=2.3.0  # Optional: for attention optimization

# Utilities
pydantic>=2.4.0
pyyaml>=6.0.1
numpy>=1.24.0
psutil>=5.9.0
aiofiles>=23.2.1

# Monitoring and Logging
prometheus-client>=0.19.0
structlog>=23.2.0

# Optional: For advanced model loading
llama-cpp-python>=0.2.11  # For GGUF models
ctransformers>=0.2.27     # Alternative GGML/GGUF loader